{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqUIc3vmg8qs",
        "outputId": "b36aab74-e599-4c12-d72a-385bbc8638d9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/ColabNotebooks/CapstoneBreath"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T57nNaHxg-Sv",
        "outputId": "0ff1c862-304a-439d-eb2f-472bbacac517"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/ColabNotebooks/CapstoneBreath\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install audiomentations soundfile librosa numpy\n",
        "!pip install torchaudio soundfile\n",
        "!pip install torch"
      ],
      "metadata": {
        "id": "j-w-4tUyNqvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import torchaudio\n",
        "import random\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import subprocess\n",
        "from glob import glob\n",
        "from torch.utils.data import Dataset\n",
        "from pathlib import Path\n",
        "from IPython.display import Audio, display\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchaudio\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "from audiomentations import Compose, AddGaussianNoise, PitchShift, Shift\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "B6RMZTD3hcWC"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
        "INPUT_DIR = \"noises/train\"\n",
        "OUTPUT_DIR = \"noises/augmented\"\n",
        "SR = 16000\n",
        "SEGMENT_SECONDS = 16\n",
        "SEGMENT_SAMPLES = SR * SEGMENT_SECONDS\n",
        "VARIANTS_PER_FILE = 50\n",
        "\n",
        "# –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏\n",
        "augment = Compose([\n",
        "    AddGaussianNoise(min_amplitude=0.0005, max_amplitude=0.002, p=0.3),\n",
        "    PitchShift(min_semitones=-1, max_semitones=1, p=0.3),\n",
        "    Shift(min_shift=0.1, max_shift=0.3, p=0.5),\n",
        "])\n",
        "\n",
        "# –§—É–Ω–∫—Ü–∏–∏ –º–∞—Å–∫–∏\n",
        "def sliding_rms(waveform, frame_size, hop_size):\n",
        "    waveform_sq = waveform ** 2\n",
        "    window = torch.ones(1, 1, frame_size)\n",
        "    return torch.sqrt(torch.nn.functional.conv1d(waveform_sq.unsqueeze(0), window, stride=hop_size) / frame_size).squeeze()\n",
        "\n",
        "def zero_crossing_rate(waveform, frame_size, hop_size):\n",
        "    waveform = waveform[0]\n",
        "    sign_changes = torch.diff(torch.sign(waveform)).abs().unsqueeze(0).unsqueeze(0)\n",
        "    window = torch.ones(1, 1, frame_size)\n",
        "    return torch.nn.functional.conv1d(sign_changes, window, stride=hop_size).squeeze() / frame_size\n",
        "\n",
        "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–∞—Å–∫–∏\n",
        "frame_size = int(0.025 * SR)\n",
        "hop_size = int(0.010 * SR)\n",
        "mask_threshold = 0.01\n",
        "\n",
        "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "files = [f for f in os.listdir(INPUT_DIR) if f.endswith(\".wav\")]\n",
        "saved_count = 0\n",
        "mask_ratios = []\n",
        "\n",
        "# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è\n",
        "for file in files:\n",
        "    wav, sr = librosa.load(os.path.join(INPUT_DIR, file), sr=SR)\n",
        "\n",
        "    # –ü–æ–≤—Ç–æ—Ä, –µ—Å–ª–∏ –∫–æ—Ä–æ—Ç–∫–∏–π\n",
        "    if len(wav) < SEGMENT_SAMPLES:\n",
        "        repeat = SEGMENT_SAMPLES // len(wav) + 1\n",
        "        wav = np.tile(wav, repeat)\n",
        "\n",
        "    basename = Path(file).stem\n",
        "    attempts = 0\n",
        "    generated = 0\n",
        "\n",
        "    while generated < VARIANTS_PER_FILE and attempts < VARIANTS_PER_FILE * 3:\n",
        "        attempts += 1\n",
        "        start = random.randint(0, len(wav) - SEGMENT_SAMPLES)\n",
        "        segment = wav[start:start + SEGMENT_SAMPLES]\n",
        "\n",
        "        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–∏—à–∫–æ–º —Ç–∏—Ö–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã\n",
        "        if np.max(np.abs(segment)) < 0.01:\n",
        "            continue\n",
        "\n",
        "        augmented = augment(samples=segment, sample_rate=SR)\n",
        "\n",
        "        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∞—Å–∫–∏\n",
        "        tensor = torch.tensor(augmented).unsqueeze(0)\n",
        "        rms = sliding_rms(tensor, frame_size, hop_size)\n",
        "        zcr = zero_crossing_rate(tensor, frame_size, hop_size)\n",
        "        mask = ((rms > 0.03) & (zcr > 0.2)).float()\n",
        "        ratio = mask.sum().item() / mask.shape[-1]\n",
        "\n",
        "        if ratio < mask_threshold:\n",
        "            continue\n",
        "\n",
        "        out_path = os.path.join(OUTPUT_DIR, f\"{basename}_aug{generated}.wav\")\n",
        "        sf.write(out_path, augmented, SR)\n",
        "        generated += 1\n",
        "        saved_count += 1\n",
        "        mask_ratios.append(ratio)\n",
        "\n",
        "avg_ratio = sum(mask_ratios) / len(mask_ratios) if mask_ratios else 0.0\n",
        "print(f\"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {saved_count} —Ñ–∞–π–ª–æ–≤ —Å mask_ratio ‚â• 1% –≤ {OUTPUT_DIR}\")\n",
        "print(f\"üìä –°—Ä–µ–¥–Ω–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –º–∞—Å–∫–∏: {avg_ratio * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "080V2G74NvzJ"
      },
      "execution_count": 47,
      "outputs": []
    }
  ]
}